#' @param model A VAST model object
#' @param data The model data used to fit the VAST model
#' @param effort A name for the column with effort information
#' @param time.table An optional table matching time to a date, used to provide year, month, and day
#'
#' @return A data frame of observed densities and counts matched to predictions
#' @export
#'
#' @examples
VASTeval<-function(model,data,effort="Effort",time.table=NA){
sim.data<-FishStatsUtils::sample_variable(Sdreport=model$parameter_estimates$SD,Obj=model$tmb_list$Obj,
variable_name="D_i",n_samples = 100)
out.data<-data.frame(data,
pDensity=model$Report$D_i/data[,effort],
pDensity_lower=apply(sim.data/data[,effort],MARGIN = 1,FUN=stats::quantile,probs=.05),
pDensity_upper=apply(sim.data/data[,effort],MARGIN = 1,FUN=stats::quantile,probs=.95),
pRedds=model$Report$D_i)
out.data$pRedds_lower<-apply(sim.data,MARGIN = 1,FUN=stats::quantile,probs=.05)
out.data$pRedds_upper<-apply(sim.data,MARGIN = 1,FUN=stats::quantile,probs=.95)
return(subset(out.data,dummy==F))
}
eval
eval<-VASTeval(model = vast.model,data = Redd.data.vast,time.table = time.table)
eval
preds
names(preds)
names(preds)[6]<-"density"
aggregate(preds$density,by=list(preds$Reach),FUN="mean")
aggregate(preds[,"density"],by=list(Reach=preds$Reach),FUN="mean")
ggplot2()+
geom_point(data=subset(preds,dummy==F),aes(x=Reach,y=density),col=1)+
geom_line(data=aggregate(preds[,"density"],by=list(Reach=preds$Reach),FUN="mean"),col=2)+
theme_bw()
library(ggplot2)
ggplot2()+
geom_point(data=subset(preds,dummy==F),aes(x=Reach,y=density),col=1)+
geom_line(data=aggregate(preds[,"density"],by=list(Reach=preds$Reach),FUN="mean"),col=2)+
theme_bw()
ggplot()+
geom_point(data=subset(preds,dummy==F),aes(x=Reach,y=density),col=1)+
geom_line(data=aggregate(preds[,"density"],by=list(Reach=preds$Reach),FUN="mean"),col=2)+
theme_bw()
preds
plotPredictionMap(data = preds,mapvar = "Density",reaches = Reach.data,
reach.names = "reachid",make.labels = F)
plotPredictionMap(data = preds,mapvar = "density",reaches = Reach.data,
reach.names = "reachid",make.labels = F)
plotPredictionMap(data = subset(preds,),mapvar = "density",reaches = Reach.data,
facet = "Year",reach.names = "reachid",make.labels = F)
plotPredictionMap(data = subset(preds,Year==2008),mapvar = "density",reaches = Reach.data,
facet = "Month",reach.names = "reachid",make.labels = F)
plotPredictionMap(data = preds,mapvar = "density",reaches = Reach.data,
reach.names = "reachid",make.labels = F)
preds
# Read in some data
data.list<-FormatStreamData(counts = "C:/Users/harj3477/Jeremy Documents/R materials/Mill_Creek/Mill_Creek_1000m_data.csv",
reaches = "C:/Users/harj3477/Jeremy Documents/R materials/Mill_Creek/Mill_Creek_1000m_reaches.shp",
surveys = "C:/Users/harj3477/Jeremy Documents/R materials/Mill_Creek/Mill_Creek_surveys.shp",
unit.conv = .0003048,makeplot = T)
Redd.data<-data.list[[1]]
Reach.data<-data.list[[2]]
Survey.data<-data.list[[3]]
vast.input0<-data.list[[4]]
vast.network<-data.list[[5]]
vast.networkLL<-data.list[[6]]
#########################################################################################
############################################################################################
#############################################################################################
#############################################################################################
#############################################################################################
settings <- make_settings(Region="stream_network",
zone=10,
purpose = "index2",
fine_scale=F,
n_x = nrow(Reach.data),
FieldConfig = c("Omega1"= 1, "Epsilon1" = 1, "Omega2" = 1, "Epsilon2" = 0),
RhoConfig = c("Beta1" = 2, "Epsilon1" = 2, "Beta2" = 2, "Epsilon2" = 0),
OverdispersionConfig = c("Eta1" = 0, "Eta2" = 0),
ObsModel = c(7, 0),
bias.correct = F,
use_anisotropy = F)
settings$Method<-"Stream_network"
settings$grid_size_km<-mean(Reach.data$Length)
Redd.data.vast.list<-MakeVASTData(data = Redd.data,reachdata = Reach.data,reddname = "Redds_Total",Time = "Biweek",
startdate = "2005-02-01",enddate = "2022-06-30",padzero = T)
Redd.data.vast<-Redd.data.vast.list[[1]]
time.table<-Redd.data.vast.list[[2]]
time.table$Day<-as.integer(format(time.table$Refdate,format="%j"))
x<-aggregate(Redd.data.vast$original[Redd.data.vast$dummy==F],
by=list(Time=Redd.data.vast$Time[Redd.data.vast$dummy==F]),FUN=max)
time.table$Original<-T
time.table$Original[time.table$Time%in%x$Time[which(x$x==0)]]<-F
Redd.data.vast.list<-MakeVASTData(data = Redd.data,reachdata = Reach.data,countname = "Redds_Total",Time = "Biweek",
startdate = "2005-02-01",enddate = "2022-06-30",padzero = T)
Redd.data.vast<-Redd.data.vast.list[[1]]
time.table<-Redd.data.vast.list[[2]]
time.table$Day<-as.integer(format(time.table$Refdate,format="%j"))
x<-aggregate(Redd.data.vast$original[Redd.data.vast$dummy==F],
by=list(Time=Redd.data.vast$Time[Redd.data.vast$dummy==F]),FUN=max)
time.table$Original<-T
time.table$Original[time.table$Time%in%x$Time[which(x$x==0)]]<-F
Redd.data.vast.list<-MakeVASTData(data = Redd.data,reachdata = Reach.data,countname = "Redds_Total",Time = "Biweek",
startdate = "2005-02-01",enddate = "2022-06-30",padzero = T)
Redd.data.vast<-Redd.data.vast.list[[1]]
time.table<-Redd.data.vast.list[[2]]
time.table
vast.input<-vast.input0[match(Redd.data.vast$Reach,vast.input0$child_i),]
# Set up covariates
covariate.data<-data.frame(Year=Redd.data.vast$Time,Lat=Redd.data.vast$Lat,Lon=Redd.data.vast$Lon,
Year2=Redd.data.vast$Year,Month=Redd.data.vast$Month,Day=Redd.data.vast$Day)
covariate.data$Week<-ceiling(covariate.data$Day/7)
covariate.data$Biweek<-factor(ceiling(covariate.data$Day/14))
vast.model<- fit_model("settings" = settings,
Lat_i = Redd.data.vast$Lat,
Lon_i = Redd.data.vast$Lon,
t_i = as.integer(Redd.data.vast$Time),
b_i = as_units(Redd.data.vast$Redds,"count"),
a_i = as_units(Redd.data.vast$Effort,"km"),
test_fit = FALSE,
PredTF_i=Redd.data.vast$dummy,
covariate_data = covariate.data,
X1_formula = ~ bs(Day,degree=5),
X1config_cp = matrix(nrow=1,ncol=5,data=1),
X2_formula = ~ bs(Day,degree=5),
X2config_cp = matrix(nrow=1,ncol=5,data=1),
input_grid=vast.input,
Network_sz=vast.network,
Network_sz_LL=vast.networkLL,
newtonsteps = 3,
Aniso=F,
getsd=T,
getHessian=T,
max_cells=nrow(Redd.data.vast),
Options = c('treat_nonencounter_as_zero' = F))
preds<-VASTpreds(model = vast.model,time.table=time.table)
model = vast.model
time.table=time.table
time="Time"
space="Reach"
#Setup
report.dims<-dim(model$Report$D_gct)
year.names<-names(model$Report$D_gct[1,1,])
if(is.null(year.names)){year.names<-1:report.dims[3]}
out.data<-data.frame(Time=rep(as.integer(year.names),each=report.dims[1]),
space=rep(1:(report.dims[1]),times=length(year.names)))
names(out.data)<-c(time,space)
# if supplied, expand the date information
if(is.data.frame(time.table)){
match.vec<-match(out.data$Time,time.table$Time)
if(time!="Year"){out.data$Year<-time.table$Year[match.vec]}
if(time!="Month"){out.data$Month<-as.integer(format(time.table$Refdate[match.vec],format="%m"))}
if(time!="Day"){out.data$Day<-as.integer(format(time.table$Refdate[match.vec],format="%j"))}
}
out.data<-cbind(out.data,data.frame(density=rep(NA,nrow(out.data)),lower=rep(NA,nrow(out.data)),
upper=rep(NA,nrow(out.data))))
# simulate the data for CIs
if(missing(sim.data)){
sim.data<-FishStatsUtils::sample_variable(Sdreport=model$parameter_estimates$SD,Obj=model$tmb_list$Obj,
variable_name="D_gct",n_samples = 100)
}
# quick loop to grab the values
for(i in 1:report.dims[3]){
spots<-(1+(i-1)*report.dims[1]):(i*report.dims[1])
out.data$density[spots]<-model$Report$D_gct[,1,i]
out.data$lower[spots]<-apply(sim.data[,1,i,],MARGIN = 1,FUN = stats::quantile,probs=.05)
out.data$upper[spots]<-apply(sim.data[,1,i,],MARGIN = 1,FUN = stats::quantile,probs=.95)
}
sim.data<-FishStatsUtils::sample_variable(Sdreport=model$parameter_estimates$SD,Obj=model$tmb_list$Obj,
variable_name="D_gct",n_samples = 100)
# quick loop to grab the values
for(i in 1:report.dims[3]){
spots<-(1+(i-1)*report.dims[1]):(i*report.dims[1])
out.data$density[spots]<-model$Report$D_gct[,1,i]
out.data$lower[spots]<-apply(sim.data[,1,i,],MARGIN = 1,FUN = stats::quantile,probs=.05)
out.data$upper[spots]<-apply(sim.data[,1,i,],MARGIN = 1,FUN = stats::quantile,probs=.95)
}
# covert density into redd predictions
input.grid<-unique(model$input_args$extra_args$input_grid)
out.data$Length<-input.grid$Area_km2[match(out.data$Reach,input.grid$child_i)]
out.data$count<-out.data$preds*out.data$Length
out.data$lowercount<-out.data$lower*out.data$Length
input.grid
out.data
# covert density into redd predictions
input.grid<-unique(model$input_args$extra_args$input_grid)
out.data$Length<-input.grid$Area_km2[match(out.data$Reach,input.grid$child_i)]
out.data$count<-out.data$preds*out.data$Length
#' @param model A VAST model object
#' @param time A name for the time variable for the output data frame
#' @param space A name for the space variable for the output data frame
#' @param time.table An optional table matching time to a date, used to provide year, month, and day
#' @param sim.data If you already have a simulated data, save time by supplying it here
#'
#' @return A data frame with density predictions with uncertainty match to space and time
#' @export
#'
#' @examples
VASTpreds<-function(model,time="Time",space="Reach",time.table=NA,sim.data){
#Setup
report.dims<-dim(model$Report$D_gct)
year.names<-names(model$Report$D_gct[1,1,])
if(is.null(year.names)){year.names<-1:report.dims[3]}
out.data<-data.frame(Time=rep(as.integer(year.names),each=report.dims[1]),
space=rep(1:(report.dims[1]),times=length(year.names)))
names(out.data)<-c(time,space)
# if supplied, expand the date information
if(is.data.frame(time.table)){
match.vec<-match(out.data$Time,time.table$Time)
if(time!="Year"){out.data$Year<-time.table$Year[match.vec]}
if(time!="Month"){out.data$Month<-as.integer(format(time.table$Refdate[match.vec],format="%m"))}
if(time!="Day"){out.data$Day<-as.integer(format(time.table$Refdate[match.vec],format="%j"))}
}
out.data<-cbind(out.data,data.frame(density=rep(NA,nrow(out.data)),lower=rep(NA,nrow(out.data)),
upper=rep(NA,nrow(out.data))))
# simulate the data for CIs
if(missing(sim.data)){
sim.data<-FishStatsUtils::sample_variable(Sdreport=model$parameter_estimates$SD,Obj=model$tmb_list$Obj,
variable_name="D_gct",n_samples = 100)
}
# quick loop to grab the values
for(i in 1:report.dims[3]){
spots<-(1+(i-1)*report.dims[1]):(i*report.dims[1])
out.data$density[spots]<-model$Report$D_gct[,1,i]
out.data$lower[spots]<-apply(sim.data[,1,i,],MARGIN = 1,FUN = stats::quantile,probs=.05)
out.data$upper[spots]<-apply(sim.data[,1,i,],MARGIN = 1,FUN = stats::quantile,probs=.95)
}
# covert density into redd predictions
input.grid<-unique(model$input_args$extra_args$input_grid)
out.data$Length<-input.grid$Area_km2[match(out.data$Reach,input.grid$child_i)]
out.data$count<-out.data$density*out.data$Length
out.data$lowercount<-out.data$lower*out.data$Length
out.data$uppercount<-out.data$upper*out.data$Length
return(out.data)
}
preds<-VASTpreds(model = vast.model,time.table=time.table)
names(preds)[6]<-"Density"
preds$Time2<-time.table$Refdate[match(preds$Time,time.table$Time)]
plotPredictionMap(data = preds,mapvar = "Density",reaches = Reach.data,
reach.names = "reachid",make.labels = F)
plotPredictionMap(data = preds,mapvar = "Density",reaches = Reach.data,
facet = "Year",reach.names = "reachid",make.labels = F)
plotPredictionMap(data = subset(preds,Year==2008),mapvar = "Density",reaches = Reach.data,
facet = "Week",reach.names = "reachid",make.labels = F)
plotPredictionMap(data = subset(preds,Year==2008),mapvar = "Density",reaches = Reach.data,
facet = "Time",reach.names = "reachid",make.labels = F)
Mill.list<-FormatStreamData(counts = Mill.data,reaches = Mill.reaches,surveys = Mill.surveys,unit.conv = .0003048)
Reach.data<-Mill.list[[2]]
Survey.data<-Mill.list[[3]]
vast.input0<-Mill.list[[4]]
vast.network<-Mill.list[[5]]
vast.networkLL<-Mill.list[[6]]
vast.input0<-Mill.list[[4]]
vast.network<-Mill.list[[5]]
vast.networkLL<-Mill.list[[6]]
We also need to produce a set of auxiliary data frames that VAST will use to determine the spatial relationships, and each of these objects requires a very specific format with specific columns and names. These are returned as elements 4-6 of the list. The object "vast.input0" requires Lon and Lat coordinates (from the midpoint of each reach), a column named "child_i" which is equivalent to the reach id, and a column for "Area_km2", which is equivalent the Area calculated above (note that we are treating stream lengths as if they are areas). We will need to further modify this object later, after choosing a temporal resolution.
## Choosing a temporal resolution
Depending on the system being modeled, a variety of temporal resolutions are possible. Therefore, we will need one additional formatting step, provided by MakeVASTData. For this example, we will set the temporal resolution to one month, and will cover the 5 months from Feb. to June. We will also pad the ends of the data set with zeros, to mark the ends of the season.
```{r}
Redd.data.vast.list<-MakeVASTData(data = Redd.data,reachdata = Reach.data,countname = "Redds",Time = "Month",
startdate = "2005-02-01",enddate = "2022-06-30",padzero = T)
Redd.data.vast<-Redd.data.vast.list[[1]]
time.table<-Redd.data.vast.list[[2]]
vast.input<-vast.input0[match(Redd.data.vast$Reach,vast.input0$child_i),]
vast.input<-vast.input0[match(Redd.data.vast$Reach,vast.input0$child_i),]
This function returns a list with two elements. The first is a data frame that contains everything we will need for VAST.This data frame has three important additions. First, the temporal element has been converted into a generic "Time" period that runs in sequence. It also includes two columns "Original" and "Dummy". The Original column identifies actual data points, while the Dummy column identifies time periods or reaches for which no data is available, but that we would like the model to output a prediction.
The second element of the list is a table that is useful for relating the time period back to it's normal calendar date. The last step is that vast.input must have a number of rows equal to Redd.data.vast, so we will pull from vast.input0 to make the full version.
## An example in VAST
From this point, we will use VAST functions to setup and run the model, and the example code here should be used as a guide. The user is advised to review the documentation for VAST, which contains extensive options for how to customize your model. Future versions of StreamVAST may include wrapper functions that automatically choose sensible options, but for now users can use the code in this document as a model. The first step is to make a settings object.
```{r}
settings <- make_settings(Region="stream_network",
zone=10,
purpose = "index2",
fine_scale=F,
n_x = nrow(Reach.data),
FieldConfig = c("Omega1"= 1, "Epsilon1" = 1, "Omega2" = 0, "Epsilon2" = 0),
RhoConfig = c("Beta1" = 2, "Epsilon1" = 2, "Beta2" = 2, "Epsilon2" = 0),
OverdispersionConfig = c("Eta1" = 0, "Eta2" = 0),
ObsModel = c(7, 0),
bias.correct = T,
use_anisotropy = F)
settings$Method<-"Stream_network"
settings$grid_size_km<-mean(Reach.data$Length)
settings <- make_settings(Region="stream_network",
zone=10,
purpose = "index2",
fine_scale=F,
n_x = nrow(Reach.data),
FieldConfig = c("Omega1"= 1, "Epsilon1" = 1, "Omega2" = 0, "Epsilon2" = 0),
RhoConfig = c("Beta1" = 2, "Epsilon1" = 2, "Beta2" = 2, "Epsilon2" = 0),
OverdispersionConfig = c("Eta1" = 0, "Eta2" = 0),
ObsModel = c(7, 0),
bias.correct = T,
use_anisotropy = F)
settings$Method<-"Stream_network"
settings$grid_size_km<-mean(Reach.data$Length)
It is important to specify that Region = "stream_network", and to set n_x equal tot he number of reaches. The zone is the UTM time zone, and purpose = "index2" specifies that our goal is abundance or density prediction. FieldConfig is turns various components of the model on or off (the example removes several terms for simplicity and stability), and RhoConfig specifies the type autocorrelation (random-walk in this case). We are not modeling the overdispersion, so these settings are set to zero. ObsModel controls the distributions and link functions in the model, with the current setting indicating a Poisson count model with zero inflation. Anisotropy and fine_scale should be turned off. Please see the VAST documentation for details.
It is also necessary to manually set the method to "Stream_network" and to calculate a mean size for the prediction frame.
For this example, we will not use any covariates, but this is the point where you would set up a covariate data set as well. See the VAST documentation for details.
Next, we can run the model, using "fit_model" from the VAST package. While there are many inputs, the preceding steps have made everything available. Note that some of the values should be converted to units for the function. Also, VAST will write a number of text files to you active working directory.
```{r, message=F,results='hide'}
vast.model<- fit_model("settings" = settings,
Lat_i = Redd.data.vast$Lat,
Lon_i = Redd.data.vast$Lon,
t_i = as.integer(Redd.data.vast$Time),
b_i = as_units(Redd.data.vast$Redds,"count"),
a_i = as_units(Redd.data.vast$Effort,"km"),
test_fit = FALSE,
PredTF_i=Redd.data.vast$dummy,
input_grid=vast.input,
Network_sz=vast.network,
Network_sz_LL=vast.networkLL,
newtonsteps = 3,
Aniso=F,
getsd=T,
getHessian=T,
max_cells=nrow(Redd.data.vast),
Options = c('treat_nonencounter_as_zero' = F))
Mill.data<-read.csv("Mill_data.csv")
Mill.reaches<-st_read("Mill_reaches.shp")
Mill.surveys<-st_read("Mill_survey_tracks.shp")
Mill.list<-FormatStreamData(counts = Mill.data,reaches = Mill.reaches,surveys = Mill.surveys,unit.conv = .0003048)
Redd.data<-Mill.list[[1]]
Reach.data<-Mill.list[[2]]
Survey.data<-Mill.list[[3]]
vast.input0<-Mill.list[[4]]
vast.network<-Mill.list[[5]]
vast.networkLL<-Mill.list[[6]]
Redd.data.vast.list<-MakeVASTData(data = Redd.data,reachdata = Reach.data,countname = "Redds",Time = "Month",
startdate = "2005-02-01",enddate = "2022-06-30",padzero = T)
Redd.data.vast<-Redd.data.vast.list[[1]]
time.table<-Redd.data.vast.list[[2]]
vast.input<-vast.input0[match(Redd.data.vast$Reach,vast.input0$child_i),]
settings <- make_settings(Region="stream_network",
zone=10,
purpose = "index2",
fine_scale=F,
n_x = nrow(Reach.data),
FieldConfig = c("Omega1"= 1, "Epsilon1" = 1, "Omega2" = 0, "Epsilon2" = 0),
RhoConfig = c("Beta1" = 2, "Epsilon1" = 2, "Beta2" = 2, "Epsilon2" = 0),
OverdispersionConfig = c("Eta1" = 0, "Eta2" = 0),
ObsModel = c(7, 0),
bias.correct = T,
use_anisotropy = F)
settings$Method<-"Stream_network"
settings$grid_size_km<-mean(Reach.data$Length)
vast.model<- fit_model("settings" = settings,
Lat_i = Redd.data.vast$Lat,
Lon_i = Redd.data.vast$Lon,
t_i = as.integer(Redd.data.vast$Time),
b_i = as_units(Redd.data.vast$Redds,"count"),
a_i = as_units(Redd.data.vast$Effort,"km"),
test_fit = FALSE,
PredTF_i=Redd.data.vast$dummy,
input_grid=vast.input,
Network_sz=vast.network,
Network_sz_LL=vast.networkLL,
newtonsteps = 3,
Aniso=F,
getsd=T,
getHessian=T,
max_cells=nrow(Redd.data.vast),
Options = c('treat_nonencounter_as_zero' = F))
vast.model$parameter_estimates$Convergence_check
preds<-VASTpreds(model = vast.model,time.table=time.table)
plotPredictionMap(data = preds,mapvar = "density",reaches = Reach.data,
reach.names = "reachid",make.labels = F)
plotPredictionMap(data = subset(preds,Year==2008),mapvar = "density",reaches = Reach.data,
facet = "Month",reach.names = "reachid",make.labels = F)
Redd.data.vast.list<-MakeVASTData(data = Redd.data,reachdata = Reach.data,countname = "Redds",Time = "BiWeek",
startdate = "2005-02-01",enddate = "2022-06-30",padzero = T)
Redd.data.vast.list<-MakeVASTData(data = Redd.data,reachdata = Reach.data,countname = "Redds",Time = "Biweek",
startdate = "2005-02-01",enddate = "2022-06-30",padzero = T)
Redd.data.vast<-Redd.data.vast.list[[1]]
time.table<-Redd.data.vast.list[[2]]
vast.input<-vast.input0[match(Redd.data.vast$Reach,vast.input0$child_i),]
Redd.data.vast.list<-MakeVASTData(data = Redd.data,reachdata = Reach.data,countname = "Redds",Time = "Month",
startdate = "2005-02-01",enddate = "2022-06-30",padzero = T)
Redd.data.vast<-Redd.data.vast.list[[1]]
time.table<-Redd.data.vast.list[[2]]
vast.input<-vast.input0[match(Redd.data.vast$Reach,vast.input0$child_i),]
settings <- make_settings(Region="stream_network",
zone=10,
purpose = "index2",
fine_scale=F,
n_x = nrow(Reach.data),
FieldConfig = c("Omega1"= 1, "Epsilon1" = 1, "Omega2" = 1, "Epsilon2" = 1),
RhoConfig = c("Beta1" = 2, "Epsilon1" = 2, "Beta2" = 2, "Epsilon2" = 2),
OverdispersionConfig = c("Eta1" = 0, "Eta2" = 0),
ObsModel = c(7, 0),
bias.correct = T,
use_anisotropy = F)
settings$Method<-"Stream_network"
settings$grid_size_km<-mean(Reach.data$Length)
vast.model<- fit_model("settings" = settings,
Lat_i = Redd.data.vast$Lat,
Lon_i = Redd.data.vast$Lon,
t_i = as.integer(Redd.data.vast$Time),
b_i = as_units(Redd.data.vast$Redds,"count"),
a_i = as_units(Redd.data.vast$Effort,"km"),
test_fit = FALSE,
PredTF_i=Redd.data.vast$dummy,
input_grid=vast.input,
Network_sz=vast.network,
Network_sz_LL=vast.networkLL,
newtonsteps = 3,
Aniso=F,
getsd=T,
getHessian=T,
max_cells=nrow(Redd.data.vast),
Options = c('treat_nonencounter_as_zero' = F))
settings <- make_settings(Region="stream_network",
zone=10,
purpose = "index2",
fine_scale=F,
n_x = nrow(Reach.data),
FieldConfig = c("Omega1"= 1, "Epsilon1" = 1, "Omega2" = 1, "Epsilon2" = 0),
RhoConfig = c("Beta1" = 2, "Epsilon1" = 2, "Beta2" = 2, "Epsilon2" = 0),
OverdispersionConfig = c("Eta1" = 0, "Eta2" = 0),
ObsModel = c(7, 0),
bias.correct = T,
use_anisotropy = F)
settings$Method<-"Stream_network"
settings$grid_size_km<-mean(Reach.data$Length)
settings <- make_settings(Region="stream_network",
zone=10,
purpose = "index2",
fine_scale=F,
n_x = nrow(Reach.data),
FieldConfig = c("Omega1"= 1, "Epsilon1" = 1, "Omega2" = 1, "Epsilon2" = 0),
RhoConfig = c("Beta1" = 2, "Epsilon1" = 2, "Beta2" = 2, "Epsilon2" = 0),
OverdispersionConfig = c("Eta1" = 0, "Eta2" = 0),
ObsModel = c(7, 0),
bias.correct = T,
use_anisotropy = F)
settings$Method<-"Stream_network"
settings$grid_size_km<-mean(Reach.data$Length)
It is important to specify that Region = "stream_network", and to set n_x equal tot he number of reaches. The zone is the UTM time zone, and purpose = "index2" specifies that our goal is abundance or density prediction. FieldConfig is turns various components of the model on or off (the example removes several terms for simplicity and stability), and RhoConfig specifies the type autocorrelation (random-walk in this case). We are not modeling the overdispersion, so these settings are set to zero. ObsModel controls the distributions and link functions in the model, with the current setting indicating a Poisson count model with zero inflation. Anisotropy and fine_scale should be turned off. Please see the VAST documentation for details.
It is also necessary to manually set the method to "Stream_network" and to calculate a mean size for the prediction frame.
For this example, we will not use any covariates, but this is the point where you would set up a covariate data set as well. See the VAST documentation for details.
Next, we can run the model, using "fit_model" from the VAST package. While there are many inputs, the preceding steps have made everything available. Note that some of the values should be converted to units for the function. Also, VAST will write a number of text files to you active working directory.
vast.model<- fit_model("settings" = settings,
Lat_i = Redd.data.vast$Lat,
Lon_i = Redd.data.vast$Lon,
t_i = as.integer(Redd.data.vast$Time),
b_i = as_units(Redd.data.vast$Redds,"count"),
a_i = as_units(Redd.data.vast$Effort,"km"),
test_fit = FALSE,
PredTF_i=Redd.data.vast$dummy,
input_grid=vast.input,
Network_sz=vast.network,
Network_sz_LL=vast.networkLL,
newtonsteps = 3,
Aniso=F,
getsd=T,
getHessian=T,
max_cells=nrow(Redd.data.vast),
Options = c('treat_nonencounter_as_zero' = F))
vast.model$parameter_estimates$Convergence_check
vast.model$parameter_estimates$par
preds<-VASTpreds(model = vast.model,time.table=time.table)
plotPredictionMap(data = preds,mapvar = "density",reaches = Reach.data,
reach.names = "reachid",make.labels = F)
plotPredictionMap(data = subset(preds,Year==2008),mapvar = "density",reaches = Reach.data,
facet = "Month",reach.names = "reachid",make.labels = F)
plotPredictionMap(data = subset(preds,Year==2016),mapvar = "density",reaches = Reach.data,
facet = "Month",reach.names = "reachid",make.labels = F)
plotPredictionMap(data = subset(preds,Year==2007),mapvar = "density",reaches = Reach.data,
facet = "Month",reach.names = "reachid",make.labels = F)
plotPredictionMap(data = subset(preds,Year==2015),mapvar = "density",reaches = Reach.data,
facet = "Month",reach.names = "reachid",make.labels = F)
plotPredictionMap(data = subset(preds,Year==2015),mapvar = "density",reaches = Reach.data,
facet = "Month",reach.names = "reachid",make.labels = F,xaxis.breaks = NA)
plotPredictionMap(data = subset(preds,Year==2015),mapvar = "density",reaches = Reach.data,
facet = "Month",reach.names = "reachid",make.labels = F,xaxis.breaks = NULL)
plotPredictionMap(data = preds,mapvar = "density",reaches = Reach.data,
reach.names = "reachid",make.labels = F)
plotPredictionMap(data = subset(preds,Year==2015),mapvar = "density",reaches = Reach.data,
facet = "Month",reach.names = "reachid",make.labels = F,xaxis.breaks = c(-123.24,-123.20))
plotPredictionMap(data = preds,mapvar = "density",reaches = Reach.data,
facet = "Month",reach.names = "reachid",make.labels = F,xaxis.breaks = c(-123.24,-123.20))
library(DHARMa)
fit<-vast.model
dharmaRes = summary(vast.model, what="residuals", type=1)
#-----------------------------------------------------------------
# load needed libraries
library(pkgdown)
#-----------------------------------------------------------------
# set up to automatically publish pkgdown site to GitHub
usethis::use_pkgdown_github_pages()
# Run once to configure your package to use pkgdown
usethis::use_pkgdown()
# check that _pkgdown.yml looks good
pkgdown::check_pkgdown()
# Run to build the website
pkgdown::build_site()
remotes::install_github("Jpharris7/StreamVAST", build_vignettes = FALSE)
library(StreamVAST)
library(VAST)
library(sf)
library(ggplot2)
library(sfnetworks)
plotPredictionMap(data = subset(preds,Year==2016),mapvar = "density",reaches = Reach.data,
facet = "Time",reach.names = "reachid",make.labels = F,xaxis.breaks = c(-123.24,-123.20))
Mill.data<-read.csv("Mill_data.csv")
summary(Mill.data)
# Run to build the website
pkgdown::build_site()
# to look at the site
pkgdown::preview_site()
#-----------------------------------------------------------------
# deploy site to gh-pages branch on GitHub
pkgdown::deploy_to_branch()
